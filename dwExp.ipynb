{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd5d3b5-ceba-469b-85e6-a6e0d1e3370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4\n",
    "# !pip install openml dimod dwave-system\n",
    "#!pip install xlsxwriter\n",
    "#!pip install dwave-ocean-sdk\n",
    "#!pip install imblearn\n",
    "# Set your DWAVE_API_TOKEN\n",
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e928b483-ef3b-4ccb-a0d4-626315e5f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import dimod\n",
    "from dwave.system import EmbeddingComposite, DWaveSampler, LeapHybridCQMSampler\n",
    "from dwave.samplers import SimulatedAnnealingSampler, TabuSampler, RandomSampler, PlanarGraphSolver, SteepestDescentSolver\n",
    "import xlsxwriter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#os.environ['DWAVE_API_TOKEN'] = 'Actual-DW-key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f987a1f-6b55-4f4f-9f20-f3313ab66ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KC4.csv\n"
     ]
    }
   ],
   "source": [
    "# Function for dataset processing\n",
    "def dataset(df, seed_value):\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Impute missing values with the mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = imputer.fit_transform(X)\n",
    "\n",
    "    X = X.astype(float)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Handle imbalanced data using SMOTE\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=seed_value)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=seed_value)\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Function for mutual information-based feature selection\n",
    "def feature_selection_mutual(X_train_scaled, X_test_scaled, y_train, solver_file='TS,default.csv'):\n",
    "    solver_name = solver_file.split(',')[0]\n",
    "    filename = solver_file.split(',')[1]\n",
    "    problem_label = f\"{solver_name}-{filename}\"\n",
    "    mutual_info_matrix_features = mutual_info_classif(X_train_scaled, y_train)\n",
    "\n",
    "    num_features = X_test_scaled.shape[1]\n",
    "    mutual_info_matrix_pairs = np.zeros((num_features, num_features))\n",
    "\n",
    "    for i in range(num_features):\n",
    "        for j in range(num_features):\n",
    "            mutual_info_matrix_pairs[i, j] = mutual_info_classif(X_train_scaled[:, i].reshape(-1, 1), y_train)\n",
    "\n",
    "    alpha = 0.99\n",
    "    Rxy = mutual_info_matrix_features\n",
    "    Q = mutual_info_matrix_pairs * (1 - alpha)\n",
    "    np.fill_diagonal(Q, -Rxy * alpha)\n",
    "\n",
    "    bqm = dimod.BinaryQuadraticModel(Q, \"BINARY\")\n",
    "\n",
    "    if solver_name == 'TS':\n",
    "        solver = TabuSampler()\n",
    "    elif solver_name == 'SA':\n",
    "        solver = SimulatedAnnealingSampler()\n",
    "    elif solver_name == 'PG':\n",
    "        solver = PlanarGraphSolver()\n",
    "    elif solver_name == 'RS':\n",
    "        solver = RandomSampler()\n",
    "    elif solver_name == 'SD':\n",
    "        solver = SteepestDescentSolver()\n",
    "    elif solver_name == 'QPU':\n",
    "        solver = EmbeddingComposite(DWaveSampler())\n",
    "    elif solver_name == 'DW':\n",
    "        cqm = dimod.ConstrainedQuadraticModel()\n",
    "        cqm.set_objective(bqm)\n",
    "        solver = LeapHybridCQMSampler()\n",
    "\n",
    "    sampleset = solver.sample(bqm, num_reads=100, label=problem_label) if solver_name != 'DW' else solver.sample_cqm(cqm, label=problem_label)\n",
    "\n",
    "    best = sorted(sampleset.data(), key=lambda x: (list(x.sample.values())[0], x.energy))[0]\n",
    "    is_selected = np.array([bool(val) for val in best.sample.values()])\n",
    "    features = np.array([i for i, val in enumerate(is_selected) if val])\n",
    "\n",
    "    X_train_selected = X_train_scaled[:, features]\n",
    "    X_test_selected = X_test_scaled[:, features]\n",
    "\n",
    "    return X_train_selected, X_test_selected, features, sampleset.info\n",
    "\n",
    "# Function to return full features\n",
    "def feature_full(X_train_scaled, X_test_scaled, y_train):\n",
    "    features = 'full'\n",
    "    info = 'X'\n",
    "    return X_train_scaled, X_test_scaled, features, info\n",
    "\n",
    "# Function to train the model and calculate metrics\n",
    "def model_accuracy(X_train, X_test, y_train, y_test, seed_value):\n",
    "    clf = SVC(probability=True, random_state=seed_value)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    y_scores = clf.decision_function(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(y_test, y_scores, multi_class='ovr')\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    g_mean = (sensitivity * specificity) ** 0.5\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    num_columns = X_train.shape[1]\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'AUC': auc,\n",
    "        'G-mean': g_mean,\n",
    "        'Matthew': mcc,\n",
    "        'Cohen': kappa,\n",
    "        'Feature No': num_columns\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    #path = '/content/drive/MyDrive/Colab Notebooks/dwExp/'\n",
    "    path = 'dw_datasets/'\n",
    "    folder_path = [path + 'NASA/', path + 'JIRA/', path + 'AEEEM/', path+'TEST/']\n",
    "    selected_path = folder_path[3]\n",
    "    num_runs = 1\n",
    "    excel_file_path = selected_path + 'results.xlsx'\n",
    "\n",
    "    dataset_file_names = [file_name for file_name in os.listdir(selected_path) if file_name.endswith('.csv')]\n",
    "    results_dict = {}\n",
    "\n",
    "    for file_name in dataset_file_names:\n",
    "        print(file_name)\n",
    "        results_df = pd.DataFrame()\n",
    "        file_path = os.path.join(selected_path, file_name)\n",
    "        csv_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Handle NASA dataset specific preprocessing\n",
    "        if 'NASA' in selected_path or 'TEST' in selected_path:\n",
    "            csv_data.replace('?', np.nan, inplace=True)\n",
    "            mapping = {'Y': 1, 'N': 0}\n",
    "            csv_data.iloc[:, -1] = csv_data.iloc[:, -1].map(mapping)\n",
    "            # Ensure that all values are correctly mapped\n",
    "            csv_data.iloc[:, -1] = pd.to_numeric(csv_data.iloc[:, -1], errors='coerce')\n",
    "\n",
    "        elif 'JIRA' in selected_path:\n",
    "            csv_data.replace('?', np.nan, inplace=True)\n",
    "            csv_data.iloc[:, -1] = csv_data.iloc[:, -1].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "        elif 'AEEEM' in selected_path:\n",
    "            csv_data.replace('?', np.nan, inplace=True)\n",
    "            mapping = {'buggy': 1, 'clean': 0}\n",
    "            csv_data.iloc[:, -1] = csv_data.iloc[:, -1].map(mapping)\n",
    "\n",
    "        # Drop columns with a single unique value or all missing values\n",
    "        csv_data = csv_data.loc[:, csv_data.nunique() != 1]\n",
    "        csv_data = csv_data.dropna(axis=1, how='all')\n",
    "\n",
    "        for run in range(num_runs):\n",
    "            seed_value = 41  # Set your desired seed value\n",
    "            X_train_scaled, X_test_scaled, y_train, y_test = dataset(csv_data, seed_value)\n",
    "\n",
    "            function_dict = {\n",
    "                'All_feature': (feature_full, (X_train_scaled, X_test_scaled, y_train)),\n",
    "                'approaches_DW_Hybrid_mutual': (feature_selection_mutual, (X_train_scaled, X_test_scaled, y_train, f'DW,{file_name}')),\n",
    "                'approaches_DW_QPU_mutual': (feature_selection_mutual, (X_train_scaled, X_test_scaled, y_train, f'QPU,{file_name}')),\n",
    "            }\n",
    "\n",
    "            for function_name, (function, args) in function_dict.items():\n",
    "                start_time = time.time()\n",
    "                X_train_selected, X_test_selected, features, info = function(*args)\n",
    "                metrics = model_accuracy(X_train_selected, X_test_selected, y_train, y_test, seed_value)\n",
    "                elapsed_time = time.time() - start_time\n",
    "\n",
    "                if isinstance(features, str) and features == 'full':\n",
    "                  feature_names = csv_data.columns.tolist()\n",
    "                else:\n",
    "                  feature_names = [csv_data.columns[idx] for idx in features]\n",
    "\n",
    "                results_df = pd.concat([results_df, pd.DataFrame({\n",
    "                    'Approach': [function_name],\n",
    "                    'Accuracy': [metrics['Accuracy']],\n",
    "                    'Precision': [metrics['Precision']],\n",
    "                    'Recall': [metrics['Recall']],\n",
    "                    'F1 Score': [metrics['F1 Score']],\n",
    "                    'AUC': [metrics['AUC']],\n",
    "                    'G-mean': [metrics['G-mean']],\n",
    "                    'Matthew': [metrics['Matthew']],\n",
    "                    'Cohen': [metrics['Cohen']],\n",
    "                    'Feature No': [metrics['Feature No']],\n",
    "                    'Elapsed Time': [elapsed_time],\n",
    "                    'Features': [', '.join(feature_names)],\n",
    "                    'Info (Micro Sec)': [info]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "        if os.path.exists(excel_file_path):\n",
    "            with pd.ExcelWriter(excel_file_path, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "                results_df.to_excel(writer, sheet_name=file_name.split('.')[0], index=False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_file_path, engine=\"xlsxwriter\") as writer:\n",
    "                results_df.to_excel(writer, sheet_name=file_name.split('.')[0], index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirDwave",
   "language": "python",
   "name": "venv_dw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
