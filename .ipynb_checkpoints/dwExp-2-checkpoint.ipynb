{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd5d3b5-ceba-469b-85e6-a6e0d1e3370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4\n",
    "# !pip install openml dimod dwave-system\n",
    "#!pip install xlsxwriter\n",
    "#!pip install dwave-ocean-sdk\n",
    "#!pip install imblearn\n",
    "# Set your DWAVE_API_TOKEN\n",
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e928b483-ef3b-4ccb-a0d4-626315e5f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import dimod\n",
    "from dwave.system import EmbeddingComposite, DWaveSampler, LeapHybridCQMSampler\n",
    "from dwave.samplers import SimulatedAnnealingSampler, TabuSampler, RandomSampler, PlanarGraphSolver, SteepestDescentSolver\n",
    "import xlsxwriter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "os.environ['DWAVE_API_TOKEN'] = 'Actual-DW-key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f987a1f-6b55-4f4f-9f20-f3313ab66ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activemq.csv\n",
      "activemq.csv : (1884, 66)\n",
      "Current Feature Set: (2545, 30) (637, 30)\n",
      "Current Feature Set: (2545, 35) (637, 35)\n",
      "Current Feature Set: (2545, 40) (637, 40)\n",
      "Current Feature Set: (2545, 45) (637, 45)\n",
      "Current Feature Set: (2545, 50) (637, 50)\n",
      "Current Feature Set: (2545, 55) (637, 55)\n",
      "Current Feature Set: (2545, 60) (637, 60)\n",
      "Current Feature Set: (2545, 65) (637, 65)\n"
     ]
    }
   ],
   "source": [
    "def dataset(df, seed_value):\n",
    "    \"\"\"\n",
    "    Prepares a dataset by imputing missing values, handling imbalanced data, and normalizing features.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): Input dataframe where the last column is the target variable.\n",
    "    - seed_value (int): Random seed for reproducibility in data splitting and SMOTE.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_scaled (numpy.ndarray): Scaled training features.\n",
    "    - X_test_scaled (numpy.ndarray): Scaled testing features.\n",
    "    - y_train (numpy.ndarray): Training labels.\n",
    "    - y_test (numpy.ndarray): Testing labels.\n",
    "\n",
    "    Notes:\n",
    "    - Missing values in the features are imputed with the mean of each column.\n",
    "    - SMOTE is used to handle class imbalance by oversampling the minority class.\n",
    "    - The data is split into training and testing sets with an 80-20 split.\n",
    "    - Features are normalized using MinMaxScaler.\n",
    "    \"\"\"\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Impute missing values with the mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = imputer.fit_transform(X)\n",
    "\n",
    "    X = X.astype(float)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Handle imbalanced data using SMOTE\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=seed_value)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=seed_value)\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "#--------------------------------------------------------------------\n",
    "def feature_selection_mutual(X_train_scaled, X_test_scaled, y_train, solver_file='TS,default.csv'):\n",
    "    \"\"\"\n",
    "    Selects features based on mutual information using a specified solver.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train_scaled (numpy.ndarray): Scaled training features.\n",
    "    - X_test_scaled (numpy.ndarray): Scaled testing features.\n",
    "    - y_train (numpy.ndarray): Training labels.\n",
    "    - solver_file (str): File identifier for selecting the solver. Format is '<solver_name>,<filename>'.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_selected (numpy.ndarray): Scaled training features with selected features.\n",
    "    - X_test_selected (numpy.ndarray): Scaled testing features with selected features.\n",
    "    - features (numpy.ndarray): Indices of selected features.\n",
    "    - sampleset_info (dict): Information about the sampling process.\n",
    "\n",
    "    Notes:\n",
    "    - The function calculates mutual information between features and selects the most informative features using binary quadratic programming.\n",
    "    - Supported solvers include TabuSampler, SimulatedAnnealingSampler, PlanarGraphSolver, RandomSampler, SteepestDescentSolver, EmbeddingComposite, and LeapHybridCQMSampler.\n",
    "    \"\"\"\n",
    "    solver_name = solver_file.split(',')[0]\n",
    "    filename = solver_file.split(',')[1]\n",
    "    problem_label = f\"{solver_name}-{filename}\"\n",
    "    mutual_info_matrix_features = mutual_info_classif(X_train_scaled, y_train)\n",
    "\n",
    "    num_features = X_test_scaled.shape[1]\n",
    "    mutual_info_matrix_pairs = np.zeros((num_features, num_features))\n",
    "\n",
    "    for i in range(num_features):\n",
    "        for j in range(num_features):\n",
    "            mutual_info_matrix_pairs[i, j] = mutual_info_classif(X_train_scaled[:, i].reshape(-1, 1), y_train)\n",
    "\n",
    "    alpha = 0.99\n",
    "    Rxy = mutual_info_matrix_features\n",
    "    Q = mutual_info_matrix_pairs * (1 - alpha)\n",
    "    np.fill_diagonal(Q, -Rxy * alpha)\n",
    "\n",
    "    bqm = dimod.BinaryQuadraticModel(Q, \"BINARY\")\n",
    "\n",
    "    if solver_name == 'TS':\n",
    "        solver = TabuSampler()\n",
    "    elif solver_name == 'SA':\n",
    "        solver = SimulatedAnnealingSampler()\n",
    "    elif solver_name == 'PG':\n",
    "        solver = PlanarGraphSolver()\n",
    "    elif solver_name == 'RS':\n",
    "        solver = RandomSampler()\n",
    "    elif solver_name == 'SD':\n",
    "        solver = SteepestDescentSolver()\n",
    "    elif solver_name == 'QPU':\n",
    "        solver = EmbeddingComposite(DWaveSampler())\n",
    "    elif solver_name == 'DW':\n",
    "        cqm = dimod.ConstrainedQuadraticModel()\n",
    "        cqm.set_objective(bqm)\n",
    "        solver = LeapHybridCQMSampler()\n",
    "\n",
    "    sampleset = solver.sample(bqm, num_reads=100, label=problem_label) if solver_name != 'DW' else solver.sample_cqm(cqm, label=problem_label)\n",
    "\n",
    "    best = sorted(sampleset.data(), key=lambda x: (list(x.sample.values())[0], x.energy))[0]\n",
    "    is_selected = np.array([bool(val) for val in best.sample.values()])\n",
    "    features = np.array([i for i, val in enumerate(is_selected) if val])\n",
    "\n",
    "    X_train_selected = X_train_scaled[:, features]\n",
    "    X_test_selected = X_test_scaled[:, features]\n",
    "\n",
    "    return X_train_selected, X_test_selected, features, sampleset.info\n",
    "#--------------------------------------------------------------------\n",
    "# Function to return full features\n",
    "def feature_full(X_train_scaled, X_test_scaled, y_train):\n",
    "    features = 'full'\n",
    "    info = 'X'\n",
    "    return X_train_scaled, X_test_scaled, features, info\n",
    "#--------------------------------------------------------------------\n",
    "def model_accuracy(X_train, X_test, y_train, y_test, seed_value):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of an SVC model on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (numpy.ndarray): Training features.\n",
    "    - X_test (numpy.ndarray): Testing features.\n",
    "    - y_train (numpy.ndarray): Training labels.\n",
    "    - y_test (numpy.ndarray): Testing labels.\n",
    "    - seed_value (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing various performance metrics:\n",
    "        - 'Accuracy': Classification accuracy.\n",
    "        - 'Precision': Weighted precision score.\n",
    "        - 'Recall': Weighted recall score.\n",
    "        - 'F1 Score': Weighted F1 score.\n",
    "        - 'AUC': Area Under the ROC Curve.\n",
    "        - 'G-mean': Geometric mean of sensitivity and specificity.\n",
    "        - 'Matthew': Matthews correlation coefficient.\n",
    "        - 'Cohen': Cohen's kappa score.\n",
    "        - 'Feature No': Number of features used.\n",
    "\n",
    "    Notes:\n",
    "    - The function uses a Support Vector Classifier (SVC) with probability estimates.\n",
    "    - Metrics include accuracy, precision, recall, F1 score, AUC, sensitivity, specificity, G-mean, MCC, and kappa.\n",
    "    \"\"\"\n",
    "    clf = SVC(probability=True, random_state=seed_value)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    y_scores = clf.decision_function(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(y_test, y_scores, multi_class='ovr')\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    g_mean = (sensitivity * specificity) ** 0.5\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    num_columns = X_train.shape[1]\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'AUC': auc,\n",
    "        'G-mean': g_mean,\n",
    "        'Matthew': mcc,\n",
    "        'Cohen': kappa,\n",
    "        'Feature No': num_columns\n",
    "    }\n",
    "#--------------------------------------------------------------------\n",
    "def get_info(dictionary, key):\n",
    "    # Check if the key exists directly in the dictionary\n",
    "    if key in dictionary:\n",
    "        return dictionary[key]\n",
    "    \n",
    "    # Check if the 'timing' key exists and the key is in the nested 'timing' dictionary\n",
    "    if 'timing' in dictionary and key in dictionary['timing']:\n",
    "        return dictionary['timing'][key]\n",
    "    \n",
    "    # Return None if the key is not found in either case\n",
    "    return '---'\n",
    "#--------------------------------------------------------------------\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to preprocess datasets, apply feature selection methods, and evaluate models.\n",
    "    The results are saved to an Excel file.\n",
    "\n",
    "    Steps:\n",
    "    1. Set file paths and directories for datasets and results.\n",
    "    2. Iterate over dataset files in the selected directory.\n",
    "    3. Preprocess each dataset based on its type (NASA, JIRA, AEEEM).\n",
    "    4. Apply feature selection methods and evaluate models.\n",
    "    5. Save the results to an Excel file, with each dataset's results in a separate sheet.\n",
    "\n",
    "    Notes:\n",
    "    - Handles different preprocessing for NASA, JIRA, and AEEEM datasets.\n",
    "    - Uses `feature_full` and `feature_selection_mutual` for feature selection.\n",
    "    - Evaluates models with `model_accuracy`.\n",
    "    \"\"\"\n",
    "    num_runs = 1\n",
    "    #data_path = '/content/drive/MyDrive/Colab Notebooks/dwExp/'\n",
    "    data_path = 'dw_datasets/'\n",
    "    result_path = 'dw_results/'\n",
    "    folder_path = [data_path + 'NASA/', data_path + 'JIRA/', data_path + 'AEEEM/', data_path+'TEST/']\n",
    "    #selected_path = folder_path[3]\n",
    "    for selected_path in folder_path[-1:]:\n",
    "        data_dir_name = selected_path.split('/')[-2] #such as NASA, JIRA, etc. \n",
    "\n",
    "        result_file_path = f'{result_path}{data_dir_name}_results.xlsx'\n",
    "\n",
    "        dataset_file_names = [file_name for file_name in os.listdir(selected_path) if file_name.endswith('.csv')]\n",
    "        results_dict = {}\n",
    "\n",
    "        for file_name in dataset_file_names:\n",
    "            print(file_name)\n",
    "            results_df = pd.DataFrame()\n",
    "            file_path = os.path.join(selected_path, file_name)\n",
    "            csv_data = pd.read_csv(file_path)\n",
    "\n",
    "            # Handle NASA dataset specific preprocessing\n",
    "            if 'NASA' in selected_path:\n",
    "                csv_data.replace('?', np.nan, inplace=True)\n",
    "                mapping = {'Y': 1, 'N': 0}\n",
    "                csv_data.iloc[:, -1] = csv_data.iloc[:, -1].map(mapping)\n",
    "                # Ensure that all values are correctly mapped\n",
    "                csv_data.iloc[:, -1] = pd.to_numeric(csv_data.iloc[:, -1], errors='coerce')\n",
    "\n",
    "            elif 'JIRA' in selected_path or 'TEST' in selected_path:\n",
    "                csv_data.replace('?', np.nan, inplace=True)\n",
    "                csv_data.iloc[:, -1] = csv_data.iloc[:, -1].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "            elif 'AEEEM' in selected_path:\n",
    "                csv_data.replace('?', np.nan, inplace=True)\n",
    "                mapping = {'buggy': 1, 'clean': 0}\n",
    "                csv_data.iloc[:, -1] = csv_data.iloc[:, -1].map(mapping)\n",
    "\n",
    "            # Drop columns with a single unique value or all missing values\n",
    "            csv_data = csv_data.loc[:, csv_data.nunique() != 1]\n",
    "            csv_data = csv_data.dropna(axis=1, how='all')\n",
    "\n",
    "            print(file_name, \":\", csv_data.shape)\n",
    "\n",
    "            for run in range(num_runs):\n",
    "                seed_value = 41  # Set your desired seed value\n",
    "                for init_feature in range(100, 801, 100):\n",
    "                    X_train_scaled, X_test_scaled, y_train, y_test = dataset(csv_data, seed_value)\n",
    "                    \n",
    "                    X_train_scaled = X_train_scaled[:, 0:init_feature]\n",
    "                    X_test_scaled = X_test_scaled[:, 0:init_feature]\n",
    "                    \n",
    "                    print(\"Current Feature Set:\", X_train_scaled.shape, X_test_scaled.shape)\n",
    "\n",
    "                    function_dict = {\n",
    "                        'All_feature': (feature_full, (X_train_scaled, X_test_scaled, y_train)),\n",
    "                        'approaches_DW_Hybrid_mutual': (feature_selection_mutual, (X_train_scaled, X_test_scaled, y_train, f'DW,{data_dir_name}_{file_name.split(\".\")[0]}')),\n",
    "                        'approaches_DW_QPU_mutual': (feature_selection_mutual, (X_train_scaled, X_test_scaled, y_train, f'QPU,{data_dir_name}_{file_name.split(\".\")[0]}')),\n",
    "                    }\n",
    "\n",
    "\n",
    "                    for function_name, (function, args) in function_dict.items():\n",
    "                        start_time = time.time()\n",
    "                        X_train_selected, X_test_selected, features, info = function(*args)\n",
    "                        metrics = model_accuracy(X_train_selected, X_test_selected, y_train, y_test, seed_value)\n",
    "                        elapsed_time = time.time() - start_time #in seconds\n",
    "\n",
    "                        if isinstance(features, str) and features == 'full':\n",
    "                            feature_names = csv_data.columns.tolist()\n",
    "                        else:\n",
    "                            feature_names = [csv_data.columns[idx] for idx in features]\n",
    "\n",
    "                        results_df = pd.concat([results_df, pd.DataFrame({\n",
    "                            'Approach': [function_name],\n",
    "                            'Accuracy': [metrics['Accuracy']],\n",
    "                            'Precision': [metrics['Precision']],\n",
    "                            'Recall': [metrics['Recall']],\n",
    "                            'F1 Score': [metrics['F1 Score']],\n",
    "                            'AUC': [metrics['AUC']],\n",
    "                            'G-mean': [metrics['G-mean']],\n",
    "                            'Matthew': [metrics['Matthew']],\n",
    "                            'Cohen': [metrics['Cohen']],\n",
    "                            'Feature No': [metrics['Feature No']],\n",
    "                            'Elapsed Time (sec)': [elapsed_time], #in seconds\n",
    "                            'qpu_access_time': [get_info(info, 'qpu_access_time')],\n",
    "                            'charge_time': [get_info(info, 'charge_time')],\n",
    "                            'run_time': [get_info(info, 'run_time')],\n",
    "                            'qpu_sampling_time': [get_info(info, 'qpu_sampling_time')],\n",
    "                            'qpu_anneal_time_per_sample': [get_info(info, 'qpu_anneal_time_per_sample')],\n",
    "                            'qpu_readout_time_per_sample': [get_info(info, 'qpu_readout_time_per_sample')],\n",
    "                            'qpu_access_overhead_time': [get_info(info, 'qpu_access_overhead_time')],\n",
    "                            'qpu_programming_time': [get_info(info, 'qpu_programming_time')],\n",
    "                            'qpu_delay_time_per_sample': [get_info(info, 'qpu_delay_time_per_sample')],\n",
    "                            'total_post_processing_time': [get_info(info, 'total_post_processing_time')],\n",
    "                            'post_processing_overhead_time': [get_info(info, 'post_processing_overhead_time')],\n",
    "                            'problem_label': [get_info(info, 'problem_label')],\n",
    "                            'problem_id': [get_info(info, 'problem_id')],\n",
    "                            'Features': [', '.join(feature_names)],\n",
    "                            'Time Unit': ['Micro Sec']\n",
    "                        })], ignore_index=True)\n",
    "\n",
    "            if os.path.exists(result_file_path):\n",
    "                with pd.ExcelWriter(result_file_path, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "                    results_df.to_excel(writer, sheet_name=file_name.split('.')[0], index=False)\n",
    "            else:\n",
    "                with pd.ExcelWriter(result_file_path, engine=\"xlsxwriter\") as writer:\n",
    "                    results_df.to_excel(writer, sheet_name=file_name.split('.')[0], index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e32f57-7360-4f09-99ba-c5e61209a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA\n",
      "JIRA\n",
      "AEEEM\n",
      "TEST\n"
     ]
    }
   ],
   "source": [
    "#Just for testing things...........\n",
    "data_path = 'dw_datasets/'\n",
    "result_path = 'dw_results/'\n",
    "folder_path = [data_path + 'NASA/', data_path + 'JIRA/', data_path + 'AEEEM/', data_path+'TEST/']\n",
    "\n",
    "for selected_path in folder_path:\n",
    "    print(selected_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5e9faf8-51b2-469f-a1ad-f371d03e8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'constraint_labels': [], 'qpu_access_time': 15987, 'charge_time': 4306878, 'run_time': 4306878, 'problem_id': '7a116022-e988-47e3-9129-193e6111a58c', 'problem_label': 'DW-TEST_MC2'}\n",
    "\n",
    "d2 = {'timing': {'qpu_sampling_time': 12732.0, 'qpu_anneal_time_per_sample': 20.0, 'qpu_readout_time_per_sample': 86.74, 'qpu_access_time': 28495.16, 'qpu_access_overhead_time': 662.84, 'qpu_programming_time': 15763.16, 'qpu_delay_time_per_sample': 20.58, 'total_post_processing_time': 23.0, 'post_processing_overhead_time': 23.0}, 'problem_id': '7d1388ee-1bbd-40f0-9a5b-e24a275ad0ea', 'problem_label': 'QPU-TEST_MC2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f6a7c89-bf54-4dc4-96e8-1229a271fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint_labels []\n",
      "qpu_access_time 15987\n",
      "charge_time 4306878\n",
      "run_time 4306878\n",
      "problem_id 7a116022-e988-47e3-9129-193e6111a58c\n",
      "problem_label DW-TEST_MC2\n",
      "\n",
      "qpu_sampling_time 12732.0\n",
      "qpu_anneal_time_per_sample 20.0\n",
      "qpu_readout_time_per_sample 86.74\n",
      "qpu_access_time 28495.16\n",
      "qpu_access_overhead_time 662.84\n",
      "qpu_programming_time 15763.16\n",
      "qpu_delay_time_per_sample 20.58\n",
      "total_post_processing_time 23.0\n",
      "post_processing_overhead_time 23.0\n",
      "problem_id 7d1388ee-1bbd-40f0-9a5b-e24a275ad0ea\n",
      "problem_label QPU-TEST_MC2\n"
     ]
    }
   ],
   "source": [
    "def show_dict(var_dict):\n",
    "    for key in var_dict: \n",
    "        if isinstance(var_dict[key], dict):\n",
    "            show_dict(var_dict[key])\n",
    "        else: \n",
    "            print(key, var_dict[key])\n",
    "\n",
    "show_dict(d1)  \n",
    "print()\n",
    "show_dict(d2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5409cd56-fbbd-428a-a4c5-9784dff7155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662.84"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getinfo2(d2, 'qpu_access_overhead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31af472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "for x in range(100, 801, 100):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b6c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4]\n",
    "print(arr[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwExpEnv",
   "language": "python",
   "name": "venv_dw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
